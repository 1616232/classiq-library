{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c62d87ba-4f4e-4f38-ace1-d7a52a38013d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Quantum Kernels and Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038449da-e37e-4764-b527-169962901836",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "## Credit card fraud detection - simple use case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d36d7c2-53ea-41a5-a636-3fe65a3a3026",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "#### QSVM on Kaggle labeled data as means to classify and detect credit card fraudulant transactions\n",
    "\n",
    "\n",
    "- Quantum Machine Learning (QML) is the aspect of research that explores the consequences of implementing machine learning on a quantum computer\n",
    "- SVM is a supervised machine learning method widely used for multiple labeled data classification.\n",
    "- SVM algorithm can be enhanced even on a noisy intermediate scale quantum computer (NISQ) by introducing kernel method.\n",
    "\n",
    "  It can be restructured so that it can exploit the properties of large dimensionality of quantum Hilbert space\n",
    "- In this demo we will present a simple use case where Quantum SVM (QSVM) algorithm will be implemented on credit card labeled data to detect fraudulent transactions\n",
    "- We will leverage Classiqs proprietary QSVM library and core capabilities to explore the rising potential in enhancing security applications\n",
    "\n",
    "\n",
    "\n",
    "#### Demostration is based on recent work published on August 2022 [[1](#HBC)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2543d1e",
   "metadata": {},
   "source": [
    "*In this demo, besides the `classiq` package, we will use the `sklearn` package*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b920a4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install scikit-learn\n",
    "! pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30533f38-de79-4541-a91c-5bd1b2d40256",
   "metadata": {
    "tags": []
   },
   "source": [
    "*Importing the required resources:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e069db-667d-4a8c-ac7d-93603edd969c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General Imports\n",
    "# Visualisation Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Scikit Imports\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976eee82-dab2-48a5-8715-090556f2f5b2",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## For TSNE visualisation\n",
    "from numpy import linalg\n",
    "from numpy.linalg import norm\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# We'll hack a bit with the t-SNE code in sklearn 0.15.2.\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# Random state.\n",
    "RS = 20150101\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# We'll use matplotlib for graphics.\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We import seaborn to make nice plots.\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except ModuleNotFoundError:\n",
    "    palette = np.array(\n",
    "        [\n",
    "            (0.4, 0.7607843137254902, 0.6470588235294118),\n",
    "            (0.9882352941176471, 0.5529411764705883, 0.3843137254901961),\n",
    "            (0.5529411764705883, 0.6274509803921569, 0.796078431372549),\n",
    "            (0.9058823529411765, 0.5411764705882353, 0.7647058823529411),\n",
    "            (0.6509803921568628, 0.8470588235294118, 0.32941176470588235),\n",
    "            (1.0, 0.8509803921568627, 0.1843137254901961),\n",
    "            (0.8980392156862745, 0.7686274509803922, 0.5803921568627451),\n",
    "            (0.7019607843137254, 0.7019607843137254, 0.7019607843137254),\n",
    "        ]\n",
    "    )\n",
    "else:\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    sns.set_palette(\"muted\")\n",
    "    sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "    palette = np.array(sns.color_palette(\"Set2\"))\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf293355-283b-4d95-8d60-4a1e82d3093d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Classiq imports\n",
    "\n",
    "from classiq import Pauli, construct_qsvm_model, execute, show, synthesize\n",
    "from classiq.applications.qsvm import QSVMFeatureMapEntanglement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bce27f-bdd5-4265-b6b2-6a7e2e771bb2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8423973-8440-4c68-939f-2bc4edce97f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "The dataset contains **transactions made by credit cards in September 2013 by European cardholders**.\n",
    "\n",
    "This dataset presents transactions that occurred in **two days**, where there were **492 frauds** out of **284,807 transactions**.\n",
    "The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "Data properties:\n",
    "- Database contains only numeric input variables which are the result of a PCA transformation.\n",
    "- Due to confidentiality issues, original features are not provided.\n",
    "- Features V1, V2, â€¦ V28 are the principal components obtained with PCA.\n",
    "- The only features which have not been transformed with PCA are 'Time' and 'Amount'.\n",
    "- Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset.\n",
    "- The feature 'Amount' is the transaction Amount.\n",
    "- Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
    "\n",
    "\n",
    "##### Data is freely available through Kaggle [[2](#Kaggle)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c573138e-8b2d-4395-8474-4262711bf192",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading the Kaggle \"Credit Card Fraud Detection\" data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84239db8-5506-4d74-83ca-68807d63da57",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "path = (\n",
    "    pathlib.Path(__file__).parent.resolve()\n",
    "    if \"__file__\" in locals()\n",
    "    else pathlib.Path(\".\")\n",
    ")\n",
    "input_file = path / \"../resources/creditcard.csv\"\n",
    "# comma delimited file as input\n",
    "kaggle_full_set = pd.read_csv(input_file, header=0)\n",
    "# presnting first 5 lines:\n",
    "kaggle_full_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb1bcee-4ba8-4410-8017-e671411d7601",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "## 1. Data Preprocessing\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366dab5d-7042-4ed8-9213-97e8b23df4fe",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Selecting training and testing data sets\n",
    "\n",
    "To proceed with the analysis, we sub-sample the dataset to make it manageable for near-term quantum simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f699508-1313-4ed1-a62e-2977c2f495fa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_NOMINAL_SIZE = 100\n",
    "TRAIN_FRAUD_SIZE = 25\n",
    "\n",
    "TEST_NOMINAL_SIZE = 50\n",
    "TEST_FRAUD_SIZE = 10\n",
    "\n",
    "PREDICTION_NOMINAL_SIZE = 50\n",
    "PREDICTION_FRAUD_SIZE = 10\n",
    "\n",
    "SHUFFLE_DATA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ba1d64-1dd3-4195-89d4-4b2cf7ac259f",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Seperating nominal (\"legit\") from fraud:\n",
    "all_fraud_set = kaggle_full_set.loc[kaggle_full_set[\"Class\"] == 1]\n",
    "all_nominal_set = kaggle_full_set.loc[kaggle_full_set[\"Class\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84701072-4956-49cc-8340-dd9eaecac36f",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Optionally shuffle data before selctive sets\n",
    "if SHUFFLE_DATA:\n",
    "    all_fraud_set = shuffle(all_fraud_set, random_state=1234)\n",
    "    all_nominal_set = shuffle(all_nominal_set, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4acdef7-bdcc-4bf7-8da0-013bac83a4e9",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Selecting data subsets\n",
    "selected_training_set = pd.concat(\n",
    "    [all_nominal_set[:TRAIN_NOMINAL_SIZE], all_fraud_set[:TRAIN_FRAUD_SIZE]]\n",
    ")\n",
    "selected_testing_set = pd.concat(\n",
    "    [\n",
    "        all_nominal_set[TRAIN_NOMINAL_SIZE : TRAIN_NOMINAL_SIZE + TEST_NOMINAL_SIZE],\n",
    "        all_fraud_set[TRAIN_FRAUD_SIZE : TRAIN_FRAUD_SIZE + TEST_FRAUD_SIZE],\n",
    "    ]\n",
    ")\n",
    "selected_prediction_set = pd.concat(\n",
    "    [\n",
    "        all_nominal_set[\n",
    "            TRAIN_NOMINAL_SIZE\n",
    "            + TEST_NOMINAL_SIZE : TRAIN_NOMINAL_SIZE\n",
    "            + TEST_NOMINAL_SIZE\n",
    "            + PREDICTION_NOMINAL_SIZE\n",
    "        ],\n",
    "        all_fraud_set[\n",
    "            TRAIN_FRAUD_SIZE\n",
    "            + TEST_FRAUD_SIZE : TRAIN_FRAUD_SIZE\n",
    "            + TEST_FRAUD_SIZE\n",
    "            + PREDICTION_FRAUD_SIZE\n",
    "        ],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97f4b59-d39f-43bd-a250-e0cfd89cc6ce",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Seperating relevant features data (excluding the \"Time\" colom) from label data\n",
    "\n",
    "kaggle_headers = list(kaggle_full_set.columns.values)  # all headers\n",
    "feature_cols = kaggle_headers[1:-1]  # excluding Time and Class headers\n",
    "label_col = kaggle_headers[-1]  # marking Class header as label\n",
    "\n",
    "selected_training_data = selected_training_set.loc[:, feature_cols]\n",
    "selected_training_labels = selected_training_set.loc[:, label_col]\n",
    "\n",
    "selected_testing_data = selected_testing_set.loc[:, feature_cols]\n",
    "selected_testing_labels = selected_testing_set.loc[:, label_col]\n",
    "\n",
    "selected_prediction_data = selected_prediction_set.loc[:, feature_cols]\n",
    "selected_prediction_true_labels = selected_prediction_set.loc[:, label_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484f0025-c9a7-47ad-89d0-5f5e5a83fa5e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Visualization of the selected data sets with t-SNE\n",
    "\n",
    "t-SNE is a technique for dimensionality reduction that is particularly suited for the visualization of high-dimensional datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902d33f0-33d4-42ef-8e5f-2d990962b597",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scatter(x, colors):\n",
    "    # We create a scatter plot.\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect=\"equal\")\n",
    "    sc = ax.scatter(x[:, 0], x[:, 1], lw=0, s=40, c=palette[colors.astype(np.int32)])\n",
    "    plt.xlim(-25, 25)\n",
    "    plt.ylim(-25, 25)\n",
    "    ax.axis(\"off\")\n",
    "    ax.axis(\"tight\")\n",
    "\n",
    "    # We add the labels for each digit.\n",
    "    txts = []\n",
    "    labels = [\"Nominal\", \"Fraud\"]\n",
    "    for i in range(2):\n",
    "        # Position of each label.\n",
    "        xtext, ytext = np.median(x[colors == i, :], axis=0)\n",
    "        txt = ax.text(xtext, ytext, labels[i], fontsize=24)\n",
    "        txt.set_path_effects(\n",
    "            [PathEffects.Stroke(linewidth=5, foreground=\"w\"), PathEffects.Normal()]\n",
    "        )\n",
    "        txts.append(txt)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02df1717-74b3-4072-a720-4e32b07d6004",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### TSNE Visualization of train data\n",
    "\n",
    "We observe that visually t-SNE shows a separation between nominal and anomalous samples.\n",
    "\n",
    "However, **sole visualization map does not allow to track all fraudulent transactions.**\n",
    "\n",
    "**This demonstrates the challenge of high-quality fraud detection.**\n",
    "\n",
    "For the sake of quick demonstration we subselcetd a very small percentage of the data. Better logic for sub selecting the training and testing datasets will effect quality of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2c3494-cd33-4f51-85f6-8877d8af63f6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "proj = TSNE(random_state=RS).fit_transform(selected_training_data)\n",
    "scatter(proj, selected_training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdc171a-f27d-447a-abd7-a81f0022a711",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### TSNE Visualization of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08035ccb-e703-4728-92c2-a7c63f2d81b2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "proj = TSNE(random_state=RS).fit_transform(selected_testing_data)\n",
    "scatter(proj, selected_testing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde31b9c-bca0-4777-af53-283718ba78f6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Reduce dimensions\n",
    "\n",
    "**Convert original features into fewer features to match the number of Qubits**\n",
    "\n",
    "We perform dimensionality reduction to match\n",
    "the number of features with the number of qubits used in\n",
    "simulation.  For this, we use principal component analysis\n",
    "and keep only the first *N_DIM* principal components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df5673a-bdc1-4286-9d0d-246b356ee17d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## choosing data dimension to encode\n",
    "N_DIM = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88123513-9449-4bd0-90b0-4ab0fc85a622",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_train = selected_training_data.values.tolist()\n",
    "sample_test = selected_testing_data.values.tolist()\n",
    "sample_predict = selected_prediction_data.values.tolist()\n",
    "\n",
    "# Reduce dimensions\n",
    "\n",
    "pca = PCA(n_components=N_DIM).fit(sample_train)\n",
    "sample_train = pca.transform(sample_train)\n",
    "sample_test = pca.transform(sample_test)\n",
    "sample_predict = pca.transform(sample_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9bf97d-4c77-4bca-ba7b-11d2ff32ab41",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Normalize\n",
    "\n",
    "We use feature-wise standard scaling, i.e.\n",
    "we subtract the mean and scale by the standard deviation for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d11dfe-80c7-4dba-aa08-25e7f6abcd34",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normalize\n",
    "std_scale = StandardScaler().fit(sample_train)\n",
    "sample_train = std_scale.transform(sample_train)\n",
    "sample_test = std_scale.transform(sample_test)\n",
    "sample_predict = std_scale.transform(sample_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dd19da-a8c9-42c7-91f9-6eae92ed9cdf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Scale\n",
    "\n",
    "Scaling each feature to a range between -$\\pi$ and $\\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898bd956-fc38-4618-b705-f61abd056718",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scale\n",
    "samples = np.append(sample_train, sample_test, axis=0)\n",
    "samples = np.append(samples, sample_predict, axis=0)\n",
    "minmax_scale = MinMaxScaler((-np.pi, np.pi)).fit(samples)\n",
    "FRAUD_TRAIN_DATA = minmax_scale.transform(sample_train)\n",
    "FRAUD_TEST_DATA = minmax_scale.transform(sample_test)\n",
    "FRAUD_PREDICT_DATA = minmax_scale.transform(sample_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098ab007-187d-44ce-a959-70de500a65f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Final preprocessed data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f497a48-9588-424a-bd39-7c1a436cdaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAUD_TRAIN_LABELS = np.array(selected_training_labels.values.tolist())\n",
    "FRAUD_TEST_LABELS = np.array(selected_testing_labels.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16034bb-8790-4115-ae75-04842af78300",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "## 2. Map data to Hilbert Space\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebed4dd-f8a0-4708-9c14-1347d12e2f91",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### FeatureMap design with Classiq\n",
    "\n",
    "The feature map is a parameterized quantum circuit, which can be described as a unitary transformation $\\mathbf{U_\\phi}(\\mathbf{x})$ on n qubits.\n",
    "\n",
    "Since the data may be non-linearly-separable in the original space, **the feature map circuit will map the classical data into Hilbert space**.\n",
    "\n",
    "The choice of which feature map circuit to use is key and may depend on the given dataset we want to classify.\n",
    "We will leverage Classiq feature map design capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90b3bb2-ae0b-4b08-86fa-62f7a3fae0ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Choose existing feature map type (or build our own)\n",
    "As an example we can choose from the well known the Second-order Pauli-Z evolution encoding circuit with 2 repetitions OR the bloch sphere circuit encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfd814e-0c8e-4c4f-b020-3402212c0003",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Choosing \"Pauli ZZ\" feature map encodign with 2 repetitions:\n",
    "pauli_zz_feature_map_function_name = \"pauli_feature_map\"\n",
    "pauli_zz_kwargs = {\n",
    "    \"paulis\": [[Pauli.Z], [Pauli.Z, Pauli.Z]],\n",
    "    \"entanglement\": QSVMFeatureMapEntanglement.FULL,\n",
    "    \"alpha\": 2,\n",
    "    \"reps\": 2,\n",
    "    \"feature_dimension\": N_DIM,\n",
    "}\n",
    "\n",
    "## Choosing \"bloch sphere\" feature map encoding:\n",
    "bloch_sphere_feature_map_function_name = \"bloch_sphere_feature_map\"\n",
    "bloch_sphere_kwargs = {\"bloch_feature_dimension\": N_DIM}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0464ebb0-d0b7-4d29-bba7-0717133ea9d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "## 3. Execute QSVM\n",
    "\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97d3434-7b1b-46c3-bd7d-42194f402d21",
   "metadata": {},
   "source": [
    "Quantum Support Vector Machines is the **Quantum version of SVM - a data classification method which separates the data using a hyperplane**.\n",
    "\n",
    "The algorithm will perform the following steps [[3](#3)]:\n",
    "\n",
    "1. **Estimating the kernel matrix**\n",
    "\n",
    "    - A quantum feature map, $\\phi(\\mathbf{x})$, naturally gives rise to a quantum kernel, $k(\\mathbf{x}_i,\\mathbf{x}_j)= \\phi(\\mathbf{x}_j)^\\dagger\\phi(\\mathbf{x}_i)$, which can be seen as a measure of similarity: $k(\\mathbf{x}_i,\\mathbf{x}_j)$ is large when $\\mathbf{x}_i$ and $\\mathbf{x}_j$ are close.\n",
    "\n",
    "    - When considering finite data, we can represent the quantum kernel as a matrix:\n",
    "    $K_{ij} = \\left| \\langle \\phi^\\dagger(\\mathbf{x}_j)| \\phi(\\mathbf{x}_i) \\rangle \\right|^{2}$.\n",
    "\n",
    "        **We can calculate each element of this kernel matrix on a quantum computer by calculating the transition amplitude**:\n",
    "        $$\n",
    "        \\left| \\langle \\phi^\\dagger(\\mathbf{x}_j)| \\phi(\\mathbf{x}_i) \\rangle \\right|^{2} =\n",
    "        \\left| \\langle 0^{\\otimes n} | \\mathbf{U_\\phi^\\dagger}(\\mathbf{x}_j) \\mathbf{U_\\phi}(\\mathbf{x_i}) | 0^{\\otimes n} \\rangle \\right|^{2}\n",
    "        $$\n",
    "\n",
    "        This provides us with an estimate of the quantum kernel matrix, which will be used in the support vector classification.\n",
    "\n",
    "\n",
    "2. **Optimizing** the dual problem by **using the classical SVM algorithm to generate a separating Hyperplane and classify the data**\n",
    "$$ L_D(\\alpha) = \\sum_{i=1}^t \\alpha_i - \\frac{1}{2} \\sum_{i,j=1}^t y_i y_j \\alpha_i \\alpha_j K(\\vec{x}_i \\vec{x}_j) $$\n",
    "    - Where $t$ is the amount of data points\n",
    "    - the $\\vec{x}_i$s are the data points\n",
    "    - $y_i$ is the label $\\in \\{-1,1\\}$ of each data point\n",
    "    - $K(\\vec{x}_i \\vec{x}_j)$ is the kernel matrix element between the $i$ and $j$ datapoints\n",
    "    - We optimize over the $\\alpha$s\n",
    "    - We expect most of the $\\alpha$s to be $0$. The $\\vec{x}_i$s that correspond to non-zero $\\alpha_i$ are called the Support Vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78dc4c2-6010-4c70-a4d8-896c59e9aeb1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Setup Classiq QSVM model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae3fe08-b1a4-4f8a-a62c-7b4e18e9edab",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Setting QSVM model with feature map and data\n",
    "\n",
    "QSVM_FRAUD_PAULI_ZZ = construct_qsvm_model(\n",
    "    train_data=FRAUD_TRAIN_DATA.tolist(),\n",
    "    train_labels=FRAUD_TRAIN_LABELS.tolist(),\n",
    "    test_data=FRAUD_TEST_DATA.tolist(),\n",
    "    test_labels=FRAUD_TEST_LABELS.tolist(),\n",
    "    predict_data=FRAUD_PREDICT_DATA.tolist(),\n",
    "    feature_map_function_name=pauli_zz_feature_map_function_name,\n",
    "    **pauli_zz_kwargs\n",
    ")\n",
    "\n",
    "QSVM_FRAUD_BLOCH_SHPERE = construct_qsvm_model(\n",
    "    train_data=FRAUD_TRAIN_DATA.tolist(),\n",
    "    train_labels=FRAUD_TRAIN_LABELS.tolist(),\n",
    "    test_data=FRAUD_TEST_DATA.tolist(),\n",
    "    test_labels=FRAUD_TEST_LABELS.tolist(),\n",
    "    predict_data=FRAUD_PREDICT_DATA.tolist(),\n",
    "    feature_map_function_name=bloch_sphere_feature_map_function_name,\n",
    "    **bloch_sphere_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74ba26f",
   "metadata": {},
   "source": [
    "### Synthesize our model and explore the generated quantum circuit\n",
    "Once we constructed our qsvm model - we synthesize and view the quantum circuit that encodes our data.\n",
    "For this we will use `classiq` built-in `synthesize` and `show` functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccf5210-84ee-4a9f-bc66-20ac655b6f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"credit_card_fraud.qmod\", \"w\") as f:\n",
    "    f.write(QSVM_FRAUD_PAULI_ZZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d304b8-e19b-4478-b69c-0510c5950dfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qprog = synthesize(QSVM_FRAUD_PAULI_ZZ)\n",
    "show(qprog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bcb48d-84c6-4c81-b475-cba637e71c86",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Run QSVM and analyze results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5573de8c-6c44-4843-96fe-3fa72292742c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train and test the data\n",
    "\n",
    "1. Build the train and test quantum kernel matrices.\n",
    "    1. **For each pair of datapoints in the training dataset $\\mathbf{x}_{i},\\mathbf{x}_j$, apply the feature map and measure the transition probability**}: $ K_{ij} = \\left| \\langle 0 | \\mathbf{U}^\\dagger_{\\Phi(\\mathbf{x_j})} \\mathbf{U}_{\\Phi(\\mathbf{x_i})} | 0 \\rangle \\right|^2 $.\n",
    "    2. **For each training datapoint $\\mathbf{x_i}$ and testing point $\\mathbf{y_i}$, apply the feature map and measure the transition probability**: $ K_{ij} = \\left| \\langle 0 | \\mathbf{U}^\\dagger_{\\Phi(\\mathbf{y_i})} \\mathbf{U}_{\\Phi(\\mathbf{x_i})} | 0 \\rangle \\right|^2 $.\n",
    "2. Use the train and **test quantum kernel matrices in a classical support vector machine classification algorithm**.\n",
    "\n",
    "\n",
    "Executing QSVM is done though the `execute` function.\n",
    "The execution results will include the accuracy of the classification and the predicted labels for the predict data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bb556d-f986-48e7-8802-22d660a89571",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = execute(qprog).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195c71a9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    \"quantum kernel classification test score:  %0.2f\"\n",
    "    % (results[0].value[\"test_score\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbe012d",
   "metadata": {},
   "source": [
    "**Result seems quite good. It's a good start! Let's analyze it further:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9108115-05ba-4c35-b21e-167a61e745ca",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Compare testing accuracy results to classical kernels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1d3128",
   "metadata": {},
   "outputs": [],
   "source": [
    "classical_kernels = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "\n",
    "for ckernel in classical_kernels:\n",
    "    classical_svc = SVC(kernel=ckernel)\n",
    "    classical_svc.fit(FRAUD_TRAIN_DATA, FRAUD_TRAIN_LABELS)\n",
    "    classical_score = classical_svc.score(\n",
    "        FRAUD_TEST_DATA, np.array(FRAUD_TEST_LABELS.tolist())\n",
    "    )\n",
    "\n",
    "    print(\"%s kernel classification test score:  %0.2f\" % (ckernel, classical_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09158ab",
   "metadata": {},
   "source": [
    "Given our simple naive training and testing set example, the **Quantum kernel gets results \"at least as good as\" the classical kernels** -  can be interpetted as **prominsing sign** and encourage deeper research. Baring in mind the following:\n",
    "- Quantum kernel machine algorithms only have the potential of quantum advantage over classical approaches if the corresponding quantum kernel is hard to estimate classically (a necessary and not always sufficient condition to obtain a quantum advantage)\n",
    "\n",
    "- However, it was proven recently [[4](#4)] that learning problems exist for which learners with access to quantum kernel methods have a quantum advantage over all classical learners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e95e852",
   "metadata": {},
   "source": [
    "### Predict data\n",
    "\n",
    "\n",
    "  Finally, we may predict unlabeled data by calculating the kernel matrix of the new datum with respect to the support vectors\n",
    "    $$ \\text{Predicted Label}(\\vec{s}) = \\text{sign} \\left( \\sum_{i=1}^t y_i \\alpha_i^* K(\\vec{x}_i , \\vec{s}) + b \\right) $$\n",
    "        - Where $\\vec{s}$ is the datapoint to be classified\n",
    "        - $\\alpha_i^*$ are the optimized $\\alpha$s\n",
    "        - And $b$ is the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07fe84d-30fe-4041-a427-9fb3f639559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = np.array(selected_prediction_true_labels.values.tolist())\n",
    "sklearn.metrics.accuracy_score(results[0].value[\"predicted_labels\"], true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94caf317-f2e9-4a0f-87ff-858552025aaa",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "\n",
    "## Quantum advantage is possible:\n",
    "\n",
    "**QSVM has the *potential* for enhancing performance, accuracy and even efficiency** in resources:\n",
    "\n",
    "- **There are limitations to the successful classical solutions when the feature space becomes large**, and the kernel functions become computationally expensive to estimate\n",
    "\n",
    "- For **certain types of data** a classifier that **exploits the quantum feature space shows better results**.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**A necessary condition to obtain a quantum advantage is that the kernel cannot be estimated classically.** Since quantum computers are not expected to be classically simulable there is a very large design space to explore.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In the future it becomes intriguing to find suitable feature maps for this technique with provable quantum advantages while providing significant improvement on real world data sets. With the ubiquity of kernel methods in machine learning, we are optimistic that our techniques will produce applications even beyond binary classification.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c67384-d50d-4fd7-859f-30ba916fdb96",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "## References\n",
    "\n",
    "\n",
    "<a id='1'>[1]</a>: [Oleksandr Kyriienko, Einar B. Magnusson \"Unsupervised quantum machine learning for fraud detection\"](https://arxiv.org/abs/2208.01203)\n",
    "\n",
    "<a id='Kaggle'>[2]</a>: [Kaggle dataset - Credit Card Fraud Detection\n",
    "Anonymized credit card transactions labeled as fraudulent or genuine](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)\n",
    "\n",
    "<a id='3'>[3]</a>: [Havl&#237;&#269;ek, V., C&#243;rcoles, A.D., Temme, K. et al. Supervised learning with quantum-enhanced feature spaces. Nature 567, 209-212 (2019)](https://doi.org/10.1038/s41586-019-0980-2)\n",
    "\n",
    "<a id='4'>[4]</a>: [Liu et al. A rigorous and robust quantum speed-up in supervised machine learning (2020)](https://arxiv.org/pdf/2010.02174.pdf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
